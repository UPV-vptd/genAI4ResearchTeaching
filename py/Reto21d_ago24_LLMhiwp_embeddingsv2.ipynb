{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4q/teEjfkvhf4kKCZCKC7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamg-upv/0Reto21d_ago24_LLMclassification/blob/main/py/Reto21d_ago24_LLMhiwp_embeddingsv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En principio este codigo funciona con un entorno de de computacion de 12GB RAM sin GPU.\n",
        "si se atascara por RAM puedo probarlo a partirlo en bloques y que vaya actualizando un fichero de resultados\n",
        "En ultima instancia me planteo compara bloques de computación para poder usar un GPU o entornos más intensivos de RAM"
      ],
      "metadata": {
        "id": "spIdvUXwcWiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparacion previa (ejecutar solo una vez)\n"
      ],
      "metadata": {
        "id": "X8FGO3RO7rWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conexion a espacios"
      ],
      "metadata": {
        "id": "DthBQ_fkXc3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#conectar con repositorio github publico para acceso a los datasets\n",
        "!git clone https://github.com/jamg-upv/0Reto21d_ago24_LLMclassification.git\n",
        "\n",
        "#conecar a google drive para guardar alli los outputs que quiera mantener (y que no se me olvide descargarlos) luego los subiré a Git para su uso posterior\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar Google Drive si aún no está montado\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "SD9kl1-cn-AW",
        "outputId": "eb51d6aa-ea03-497c-ab48-0909362beb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '0Reto21d_ago24_LLMclassification'...\n",
            "remote: Internal Server Error\n",
            "fatal: unable to access 'https://github.com/jamg-upv/0Reto21d_ago24_LLMclassification.git/': The requested URL returned error: 500\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6f6afdba6a75>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Montar Google Drive si aún no está montado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parametrización de variables"
      ],
      "metadata": {
        "id": "xvXuHnNnSZZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define el nombre del archivo y el path de salida\n",
        "input_file_name = 'hiwp_componentsv2.csv'\n",
        "# estructura del archivo de datos:\n",
        "# Component\tDescription\tType\tClass\n",
        "\n",
        "input_path = '/content/0Reto21d_ago24_LLMclassification/datasets/'\n",
        "\n",
        "output_path = '/content/drive/MyDrive/Reto21dias_24/'\n",
        "\n",
        "# Construye el path completo\n",
        "full_in_path = os.path.join(input_path, input_file_name)\n",
        "full_in_path\n",
        "# full_out_path = os.path.join(output_path, file_name)\n",
        "\n",
        "# Define la variable con el nombre de la columna\n",
        "target_column = 'Description'\n",
        "\n",
        "# Objetos a clasificar\n",
        "selec_objects = ['art']\n",
        "\n",
        "#categorias en la que quiero clasificar los objetos\n",
        "selec_categories = ['cat1', 'cat2', 'cat3','cat4']\n",
        "\n",
        "# el identificador [component] de la categoria que quiero mostrar en el resumen de clasificación global\n",
        "target_category ='HIWPshortDescrip'\n",
        "# target_category ='HIWPLongDescrip'\n"
      ],
      "metadata": {
        "id": "WVOoxtMCSpux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar el archivo de datos y filtrar los objetos a clasificar y las categorias a utilizar para la clasificación\n",
        "\n",
        "Crea el DataFrame objects filtrando hiwp_data para incluir solo las filas donde el valor en la columna 'Type' está en la lista selec_objects.\n",
        "Crea el DataFrame categories filtrando hiwp_data para incluir solo las filas donde el valor en la columna 'Type' está en la lista selec_categories.\n",
        "\n",
        "Si necesito que la comparación no sea sensible a mayúsculas/minúsculas, puedes modificar el código así:\n",
        "\n",
        "```\n",
        "objects = hiwp_data[hiwp_data['Type'].str.lower().isin([x.lower() for x in selec_objects])]\n",
        "categories = hiwp_data[hiwp_data['Type'].str.lower().isin([x.lower() for x in selec_categories])]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "E9vQnWUeSm1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Leer el archivo CSV (es un CSV de Open Office si lo genero con MSexcel no se mapea bien sin dar atributos adicionales)\n",
        "hiwp_data = pd.read_csv(full_in_path)\n",
        "\n",
        "# Mostrar el DataFrame resultante\n",
        "# print(hiwp_data)\n",
        "\n",
        "# Crear el DataFrame 'objects'\n",
        "objects = hiwp_data[hiwp_data['Type'].isin(selec_objects)]\n",
        "\n",
        "# Crear el DataFrame 'categories'\n",
        "categories = hiwp_data[hiwp_data['Type'].isin(selec_categories)]\n",
        "\n",
        "# Opción 1: Reconstruir el índice descartando el índice original\n",
        "# objects= objects.reset_index(drop=True)\n",
        "# categories= categories.reset_index(drop=True)\n",
        "\n",
        "# Opción 2: Reconstruir el índice manteniendo el índice original como una nueva columna\n",
        "objects= objects.reset_index()\n",
        "categories= categories.reset_index()\n",
        "\n",
        "\n",
        "# Verificar los resultados\n",
        "print(\"DataFrame 'objects':\")\n",
        "print(objects.shape)\n",
        "print(objects['Type'].value_counts())\n",
        "print(\"\\nPrimeras filas de 'objects':\")\n",
        "print(objects.head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "print(\"DataFrame 'categories':\")\n",
        "print(categories.shape)\n",
        "print(categories['Type'].value_counts())\n",
        "print(\"\\nPrimeras filas de 'categories':\")\n",
        "print(categories.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkStor1tSnr3",
        "outputId": "f9e4a1b6-d92b-4c5e-a30d-137ee7cbdc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame 'objects':\n",
            "(7, 5)\n",
            "Type\n",
            "art    7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Primeras filas de 'objects':\n",
            "   index     Component                                        Description  \\\n",
            "0     18     Hauff2022  High-performance work practices, employee well...   \n",
            "1     19      Song2021  High involvement work systems and organization...   \n",
            "2     20    Marin 2016  Deconstructing AMO framework: a systematic rev...   \n",
            "3     21     Ahmad2022  The impact of green HRM on green creativity: m...   \n",
            "4     22  Houeland2022  Not my task': Role perceptions in a green tran...   \n",
            "\n",
            "  Type Class  \n",
            "0  art     1  \n",
            "1  art     1  \n",
            "2  art     1  \n",
            "3  art     0  \n",
            "4  art     0  \n",
            "\n",
            "==================================================\n",
            "\n",
            "DataFrame 'categories':\n",
            "(18, 5)\n",
            "Type\n",
            "cat1    12\n",
            "cat4     4\n",
            "cat2     1\n",
            "cat3     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Primeras filas de 'categories':\n",
            "   index           Component  \\\n",
            "0      0  Select&Recruitment   \n",
            "1      1            Training   \n",
            "2      2         Empowerment   \n",
            "3      3         PerformEval   \n",
            "4      4       Compensations   \n",
            "\n",
            "                                         Description  Type  Class  \n",
            "0  Rigorous Selection and Recruitment Selecting t...  cat1   long  \n",
            "1  Continuous Training and Development Investing ...  cat1   long  \n",
            "2  Employee participation Autonomy and Empowermen...  cat1   long  \n",
            "3  Performance Evaluation and Feedback Providing ...  cat1  short  \n",
            "4  Competitive Compensation and Benefits Offering...  cat1   long  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Embeedings\n",
        "Quiero hacer tareas de vectorizacion con google collab y dispongo de 12gb de ram (sin GPU) salvo que pase a la versión de pago. La tarea que quiero hacer es vectorizar/embeedings celdas de texto (de unas 200 palabras como máximo cada una). Todos los textos son en inglés. los embbedings los quiero utilizar para una tarea de clasificación de textos cientificos (la entrada es titulo y abstracr en la celda a vectorizar) y tengo varias categorias (con una definicion de la categoria que tambien querría vectorizar) y luego calcular la distancia entre cada articulo y cada categoria\n",
        "\n"
      ],
      "metadata": {
        "id": "Djbdr5_wJvRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pendiente\n",
        "\n",
        "* guardar los embeedings en un csv de cada uno de los modelos (con el nombre que toque. decidir si son un csv por modelo  a una tabla donde estén todos juntos por filas (ojo que cada uno tendrá una dimensión distinta). mejor una excel y cada uno una pestaña diferente y así lo puedo leer cada vez\n",
        "* idem con guardar las distancias de coseno\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4E0gWCZAZkzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Instalar las dependencias necesarias\n",
        "import pkg_resources\n",
        "import subprocess\n",
        "\n",
        "required_packages = [\n",
        "    'seaborn',\n",
        "    'matplotlib',\n",
        "    'sentence-transformers',\n",
        "    'pandas',\n",
        "    'numpy',\n",
        "    'transformers',\n",
        "    'torch'\n",
        "]\n",
        "\n",
        "installed_packages = {pkg.key for pkg in pkg_resources.working_set}\n",
        "\n",
        "for package in required_packages:\n",
        "    if package in installed_packages:\n",
        "        print(f\"{package} ya está instalado.\")\n",
        "    else:\n",
        "        print(f\"{package} no está instalado. Instalando...\")\n",
        "        subprocess.check_call([\"pip\", \"install\", package])\n",
        "        print(f\"{package} ha sido instalado.\")\n",
        "\n",
        "print(\"\\nTodas las bibliotecas necesarias están ahora instaladas.\")\n",
        "\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "LJD6g8svhpM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2067abf0-503c-47f1-c932-e9e69bd3ba5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seaborn ya está instalado.\n",
            "matplotlib ya está instalado.\n",
            "sentence-transformers no está instalado. Instalando...\n",
            "sentence-transformers ha sido instalado.\n",
            "pandas ya está instalado.\n",
            "numpy ya está instalado.\n",
            "transformers ya está instalado.\n",
            "torch ya está instalado.\n",
            "\n",
            "Todas las bibliotecas necesarias están ahora instaladas.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener la fecha y hora actual para los nombres de archivo\n",
        "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Lista de modelos a probar (con los ejemplos ha llegado a un tope de 6gb de ram)\n",
        "models_to_test = [\n",
        "    'all-MiniLM-L6-v2',\n",
        "    'all-distilroberta-v1',\n",
        "    'all-mpnet-base-v2',\n",
        "    'paraphrase-multilingual-mpnet-base-v2',\n",
        "    'distiluse-base-multilingual-cased-v1',\n",
        "    'all-MiniLM-L12-v2',\n",
        "    'allenai-specter',\n",
        "    # 'allenai/scibert_scivocab_uncased',\n",
        "    # 'distilbert-base-nli-mean-tokens',\n",
        "    # 'roberta-base-nli-stsb-mean-tokens',\n",
        "    # 'distiluse-base-multilingual-cased-v2',\n",
        "    # 'paraphrase-multilingual-MiniLM-L12-v2',\n",
        "    # 'stsb-roberta-large',\n",
        "    # 'bert-base-nli-mean-tokens'\n",
        "]\n",
        "\n",
        "# Función para evaluar un modelo\n",
        "def evaluate_model(model_name, objects_df, categories_df):\n",
        "    print(f\"Evaluating model: {model_name}\")\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Generar embeddings para objetos\n",
        "    object_texts = objects_df['Description'].tolist()\n",
        "    object_embeddings = model.encode(object_texts, show_progress_bar=True)\n",
        "\n",
        "    # Generar embeddings para categorías\n",
        "    category_texts = categories_df['Description'].tolist()\n",
        "    category_embeddings = model.encode(category_texts, show_progress_bar=True)\n",
        "\n",
        "    # Calcular similitud coseno\n",
        "    similarity_matrix = util.cos_sim(object_embeddings, category_embeddings)\n",
        "\n",
        "    # Encontrar las mejores coincidencias\n",
        "    best_matches = np.argmax(similarity_matrix, axis=1)\n",
        "\n",
        "    end_time = time.time()\n",
        "    processing_time = end_time - start_time\n",
        "\n",
        "    return {\n",
        "        'model': model_name,\n",
        "        'best_matches': categories_df.iloc[best_matches]['Component'].tolist(),\n",
        "        'processing_time': round(processing_time, 2),  # Redondear a 2 decimales\n",
        "        'embedding_size': object_embeddings.shape[1],\n",
        "        'similarity_matrix': similarity_matrix,\n",
        "        'object_embeddings': object_embeddings,\n",
        "        'category_embeddings': category_embeddings\n",
        "    }\n",
        "\n",
        "# Evaluar todos los modelos\n",
        "results = []\n",
        "similarity_data = []\n",
        "embeddings_data = []\n",
        "\n",
        "for model_name in models_to_test:\n",
        "    try:\n",
        "        result = evaluate_model(model_name, objects, categories)\n",
        "        results.append({\n",
        "            'model': result['model'],\n",
        "            'best_matches': result['best_matches'],\n",
        "            'processing_time': result['processing_time'],\n",
        "            'embedding_size': result['embedding_size']\n",
        "        })\n",
        "\n",
        "        # Preparar datos de similitud para este modelo\n",
        "        for i, obj in enumerate(objects['Component']):\n",
        "            row = [model_name, obj] + result['similarity_matrix'][i].tolist()\n",
        "            similarity_data.append(row)\n",
        "\n",
        "        # Preparar datos de embeddings para este modelo\n",
        "        for i, obj in enumerate(objects['Description']):\n",
        "            embeddings_data.append([model_name, objects['Component'].iloc[i], obj, result['object_embeddings'][i].tolist()])\n",
        "        for i, cat in enumerate(categories['Description']):\n",
        "            embeddings_data.append([model_name, categories['Component'].iloc[i], cat, result['category_embeddings'][i].tolist()])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating {model_name}: {str(e)}\")\n",
        "\n",
        "# Crear DataFrame con resultados\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results = df_results.rename(columns={'processing_time': 'processing_time_seconds'})\n",
        "print(df_results)\n",
        "\n",
        "# Crear DataFrame de similitud coseno\n",
        "columns = ['Model', 'Object'] + categories['Component'].tolist()\n",
        "df_similarity = pd.DataFrame(similarity_data, columns=columns)\n",
        "\n",
        "# Crear DataFrame de embeddings\n",
        "df_embeddings = pd.DataFrame(embeddings_data, columns=['Model', 'Component', 'Description', 'Embedding'])\n",
        "\n",
        "# Crear la nueva tabla de similitud para HIWPshortDescription\n",
        "df_hiwp_similarity = df_similarity[['Model', 'Object', target_category]].copy()\n",
        "df_hiwp_similarity.columns = ['Model', 'Object_Description', 'Similarity']\n",
        "df_hiwp_similarity['Object_Component'] = objects['Component'].tolist() * len(models_to_test)\n",
        "df_hiwp_similarity = df_hiwp_similarity[['Model', 'Object_Component', 'Object_Description', 'Similarity']]\n",
        "df_hiwp_similarity = df_hiwp_similarity.sort_values(['Model', 'Similarity'], ascending=[True, False])\n"
      ],
      "metadata": {
        "id": "52Ci32ItW0xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula el rango de similitud para cada modelo individualmente, donde el rango 1 es el mejor (mayor similitud).\n",
        "# Calcula el rango promedio para cada Object_Description a través de todos los modelos.\n",
        "# Ordena los objetos por su rango promedio (el más bajo es el mejor).\n",
        "# Guarda esta tabla resumen simplificada en un nuevo archivo CSV.\n",
        "# La tabla resumen final contendrá las siguientes columnas:\n",
        "# # Object_Component: El componente del objeto.\n",
        "# # Object_Description: La descripción del objeto.\n",
        "# # Average_Rank: El rango promedio del objeto a través de todos los modelos (más bajo es mejor).\n",
        "# Los objetos estarán ordenados por su rango promedio,\n",
        "# lo que  dará una visión integrada de cómo se comportan a través de todos los modelos\n",
        "# en relación con HIWPshortDescription.\n",
        "# No es sencillo poner un punto de corte a partir del cual se consideran \"excluidos\" los objetos a clasificar.\n",
        "# de modo que se haría un escreening por titulo y abstract mnual.\n",
        "# partienod del orden de esta tabla hasta llegar aun  punto donde\n",
        "# haya varios seguidos sin seleccionar. Momento en el que se podría parar el screening asistido por\n",
        "# clasificacion automática.\n",
        "\n",
        "# Función para calcular el rango inverso (el más alto obtiene el rango 1)\n",
        "def inverse_rank(series):\n",
        "    return series.rank(ascending=False, method='min')\n",
        "\n",
        "# Calcular rangos para cada modelo\n",
        "df_ranks = df_hiwp_similarity.groupby('Model').apply(lambda x: x.assign(Rank=inverse_rank(x['Similarity']))).reset_index(drop=True)\n",
        "\n",
        "# Calcular el rango promedio para cada Object_Component a través de todos los modelos\n",
        "df_summary = df_ranks.groupby('Object_Component')['Rank'].mean().reset_index()\n",
        "df_summary = df_summary.rename(columns={'Rank': 'Average_Rank'})\n",
        "\n",
        "# Añadir la Description correspondiente a cada Component\n",
        "df_summary = df_summary.merge(objects[['Component', 'Description']], left_on='Object_Component', right_on='Component', how='left')\n",
        "\n",
        "# Ordenar por rango promedio (ascendente, ya que el rango más bajo es mejor)\n",
        "df_summary = df_summary.sort_values('Average_Rank')\n",
        "\n",
        "# Reordenar las columnas\n",
        "df_summary = df_summary[['Object_Component', 'Description', 'Average_Rank']]\n",
        "\n",
        "# Mostrar las primeras filas de la tabla resumen\n",
        "print(df_summary.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFNE3e7c6NAJ",
        "outputId": "71abda80-74b3-45b4-cc79-548def24b2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Object_Component                                        Description  \\\n",
            "5       Marin 2016  Deconstructing AMO framework: a systematic rev...   \n",
            "3        Hauff2022  High-performance work practices, employee well...   \n",
            "6         Song2021  High involvement work systems and organization...   \n",
            "0        Ahmad2022  The impact of green HRM on green creativity: m...   \n",
            "1       Becker2022  Surviving remotely: How job control and loneli...   \n",
            "2      Burbano2022  Mitigating Gig and Remote Worker Misconduct: E...   \n",
            "4     Houeland2022  Not my task': Role perceptions in a green tran...   \n",
            "\n",
            "   Average_Rank  \n",
            "5           1.0  \n",
            "3           2.5  \n",
            "6           3.0  \n",
            "0           5.0  \n",
            "1           5.0  \n",
            "2           5.5  \n",
            "4           6.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# código para guardar todos los DataFrames en un único archivo Excel, con cada DataFrame en una hoja separada\n",
        "\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "\n",
        "# Asegurarse de que la carpeta de salida existe\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# Crear el nombre del archivo Excel\n",
        "excel_filename = f'hiwp_all_csv_classification_{current_time}_{target_category}.xlsx'\n",
        "excel_path = os.path.join(output_path, excel_filename)\n",
        "\n",
        "# Crear un ExcelWriter object\n",
        "with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
        "    # Guardar cada DataFrame en una hoja separada\n",
        "    df_results.to_excel(writer, sheet_name='model_comparison_results', index=False)\n",
        "    df_similarity.to_excel(writer, sheet_name='tablas_similitud_coseno', index=False)\n",
        "    df_embeddings.to_excel(writer, sheet_name='embeddings', index=False)\n",
        "    df_hiwp_similarity.to_excel(writer, sheet_name='hiwp_similarity', index=False)\n",
        "    df_summary.to_excel(writer, sheet_name='hiwp_similarity_summary', index=False)\n",
        "\n",
        "print(f\"Todos los resultados han sido guardados en {excel_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2-Jj3-GrwW4",
        "outputId": "927c1991-cbb1-423b-af58-536f0c2297d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todos los resultados han sido guardados en /content/drive/MyDrive/Reto21dias_24/hiwp_all_csv_classification_20240814_114333.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#si prefiero exportar como csv separado cada resultado\n",
        "# Guardar\n",
        "# Asegurarse de que la carpeta de salida existe\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# Guardar resultados\n",
        "results_path = os.path.join(output_path, f'model_comparison_results_{current_time}.csv')\n",
        "df_results.to_csv(results_path, index=False)\n",
        "print(f\"Resultados de comparación guardados en {results_path}\")\n",
        "\n",
        "# Guardar DataFrame de similitud coseno\n",
        "similarity_path = os.path.join(output_path, f'tablas_similitud_coseno_{current_time}.csv')\n",
        "df_similarity.to_csv(similarity_path, index=False)\n",
        "print(f\"Tablas de similitud coseno guardadas en {similarity_path}\")\n",
        "\n",
        "# Guardar DataFrame de embeddings\n",
        "embeddings_path = os.path.join(output_path, f'embeddings_{current_time}.csv')\n",
        "df_embeddings.to_csv(embeddings_path, index=False)\n",
        "print(f\"Embeddings guardados en {embeddings_path}\")\n",
        "\n",
        "# guardar la nueva tabla de similitud para HIWPshortDescription\n",
        "hiwp_similarity_path = os.path.join(output_path, f'hiwp_similarity_{current_time}.csv')\n",
        "df_hiwp_similarity.to_csv(hiwp_similarity_path, index=False)\n",
        "print(f\"Tabla de similitud para HIWPshortDescrip guardada en {hiwp_similarity_path}\")\n",
        "\n",
        "# Guardar la tabla resumen\n",
        "summary_path = os.path.join(output_path, f'hiwp_similarity_summary_{current_time}.csv')\n",
        "df_summary.to_csv(summary_path, index=False)\n",
        "print(f\"Tabla resumen de similitud para HIWPshortDescription guardada en {summary_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22bHVBa4qnnb",
        "outputId": "5b8afa26-6bc5-4ea5-ff8c-1bb28bada20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados de comparación guardados en /content/drive/MyDrive/Reto21dias_24/model_comparison_results_20240814_114333.csv\n",
            "Tablas de similitud coseno guardadas en /content/drive/MyDrive/Reto21dias_24/tablas_similitud_coseno_20240814_114333.csv\n",
            "Embeddings guardados en /content/drive/MyDrive/Reto21dias_24/embeddings_20240814_114333.csv\n",
            "Tabla de similitud para HIWPshortDescrip guardada en /content/drive/MyDrive/Reto21dias_24/hiwp_similarity_20240814_114333.csv\n",
            "Tabla resumen de similitud para HIWPshortDescription guardada en /content/drive/MyDrive/Reto21dias_24/hiwp_similarity_summary_20240814_114333.csv\n"
          ]
        }
      ]
    }
  ]
}